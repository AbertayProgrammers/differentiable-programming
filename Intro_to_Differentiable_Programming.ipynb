{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Differentiable_Programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbertayProgrammers/differentiable-programming/blob/master/Intro_to_Differentiable_Programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmtK7oKRJ9yT",
        "colab_type": "text"
      },
      "source": [
        "#Intro to Differentiable Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-_ryEp4KS7C",
        "colab_type": "text"
      },
      "source": [
        "Usually, writing a computer program involves explicitly specifying all the steps involved, using loops, if..else blocks, and other standard programming language features. \n",
        "\n",
        "[Differentiable programming](https://en.wikipedia.org/wiki/Differentiable_programming) involves a different process, where a program is *trained* to produce the desired outputs using a set of examples. These examples contain some data (such as images or numeric records) to input into the program, and the output which the program should produce when this data is given as its input. This is the technique behind deep leanring algorithms/artifical neural networks, which power most modern 'AI' applications. [See this article](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/) for an explanation of machine learning, deep learning and artificial intelligence.\n",
        "\n",
        "A good example of when this approach would be useful is image recognition. Trying to manually design a program to do this would be extremely complicated, but using an artificial neural network, and a dataset of images and labels of the objects they contain, we can train a program to accurately recognise images.\n",
        "\n",
        "The details of this approach can be quite complicated, but there are many high-level libraries which allow us to create and train models like this in only a few lines of code. We'll see how to do this using the [fastai](https://docs.fast.ai) and [PyTorch](https://pytorch.org) libries in Python, to get an idea of how differentiable programming works in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPmDB_M5fgDB",
        "colab_type": "text"
      },
      "source": [
        "##Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipL1F7LEacT3",
        "colab_type": "text"
      },
      "source": [
        "First, make sure this notebook is running and GPU acceleration is enabled. Click the 'Runtime' menu, select 'Change runtime type' and make sure GPU is selected as the hardware accelerator. Once this is set, click the Connect button in the upper righthand area of the page (if it does not already say 'Connected')."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHZc7xQybZiE",
        "colab_type": "text"
      },
      "source": [
        "Once the notebook is running, run the code cell below by clicking inside it and pressing Ctrl+Enter, or clicking the play button on the lefthand side of the cell. This first code cell will install the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvlZX0dASeLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hit Ctrl-Enter in here to run this code\n",
        "! curl -s https://course.fast.ai/setup/colab | bash\n",
        "! pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eZCm2flb4Yk",
        "colab_type": "text"
      },
      "source": [
        "The training dataset we'll be using comes from [Kaggle](https://www.kaggle.com), an online platform for machine learning competitions. To make sure you can download the data from Kaggle, follow the steps below.\n",
        "\n",
        "*   Go to https://www.kaggle.com and create an account\n",
        "*   Go to https://www.kaggle.com/your_username/account (substituting your_username for your actual username) and click Create New API Token. This will download a file called kaggle.json. \n",
        "* Open kaggle.json in Notepad or any text editor\n",
        "* Select the whole file (which should be very short) and paste it into the command below, replacing kaggle_json_text (but keeping the single quotes).\n",
        "* Run the code cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxkD_Cj1S0tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! echo 'kaggle_json_text' > kaggle.json\n",
        "! mkdir -p ~/.kaggle/\n",
        "! mv kaggle.json ~/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVZvDuNYfIQ3",
        "colab_type": "text"
      },
      "source": [
        "After this, run the next four code cells to set some settings for the notebook, import all the required libraries and set the random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqg323D2Sqi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IPython magic commands - this notebook is a Jupyter notebook interactive python environment\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFEZAFC5SxZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fastai library\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "# PyTorch library (fastai is built on PyTorch)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Python image library\n",
        "from PIL import Image\n",
        "# a library for showing progress bars\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DEL16PdZCx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5-4Ew6EeXXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# disable warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQQsMqYPTF53",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y76HEhytfykQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Run the next four cells to set up the needed directories and download the data from kaggle.  If you haven't seen this syntax for working with folder and file paths before, and are interested, take a look at Python 3's [pathlib](https://docs.python.org/3/library/pathlib.html).\n",
        "\n",
        "The dataset we'll be using is of images of plant seedlings. This is a handy dataset for this example since it contains 12 similar-looking categories of object to identify (training an image regognition program won't be overly easy) but it's small enough to train fairly quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTMtkFhLTEW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the dataset path\n",
        "dataset_path = Config.data_path()/'seedlings'\n",
        "# make sure this folder is created\n",
        "dataset_path.mkdir(parents=True, exist_ok=True)\n",
        "# output the path\n",
        "dataset_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7hoYouLTcvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle competitions download -c plant-seedlings-classification -f train.zip -p {dataset_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2M-1jHwTobj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -q -n {dataset_path}/train.zip -d {dataset_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBXB0E-UDsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = dataset_path/'train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVJzxkHEgCCr",
        "colab_type": "text"
      },
      "source": [
        "Once the data has been downloaded, run the cell below to print out all the categories present in the data. There should be 12 categories of plant which we will attempt to teach an artificial neural network to recognise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6v1OVwdUKFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = sorted([f.name for f in train_path.ls()]); categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFsUAbg2gcOT",
        "colab_type": "text"
      },
      "source": [
        "We'll need to split the dataset into two, so we can train the model on one part and then test it on another, to check whether it performs well on data which it has not previously seen. Run the next 6 cells to do that, and show how many samples are in each section of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrl79wuPUTIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a path for the validation set\n",
        "valid_path = dataset_path/'valid'\n",
        "valid_path.mkdir(exist_ok=True)\n",
        "# create subfolders for each category\n",
        "for category in categories:\n",
        "  (valid_path/category).mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEv4BKKtUyv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to print out how many samples of each category are present in a dataset folder\n",
        "def show_num_samples(path):\n",
        "  for category in categories:\n",
        "    print('{0:<25} {1:>15}'.format(category + \"\", str(len((path/category).ls())) + \" samples\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jqqRbaXVHOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_num_samples(train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9z7DIQDXJd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomly move 20% of the data to the validation set\n",
        "random.seed(42)\n",
        "for category in categories:\n",
        "  for file in (train_path/category).ls():\n",
        "    if random.randint(1, 10) >= 8:\n",
        "      shutil.move(file, valid_path/category/file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkG98D2AYCPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_num_samples(train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXd7dFS3YEg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_num_samples(valid_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLMndSQwyPVT",
        "colab_type": "text"
      },
      "source": [
        "Before moving on, if at any point you want to check the documentation for any of the features of fastai or any other library, type in a question mark before the name of a class or function and run the cell - this will show you some documentation. Two question marks will show you the source code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMfurmRFyEWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?ImageDataBunch.from_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZy3hWGsg5jQ",
        "colab_type": "text"
      },
      "source": [
        "Once all the image files are in the right place, we can load the datasets using the fastai library, and display a few of the images to visualise the dataset. We'll name the dataset clean_data, because later we'll investigate how to alter the data in order to fool the model, exposing some of the potential weaknesses of these artificial neural network models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhwkxejYYGxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a fastai ImageDataBunch using the training set and validation sets we've created\n",
        "# size is the image size (224x224) and bs is the batch size\n",
        "clean_data = ImageDataBunch.from_folder(dataset_path, \n",
        "  train='train', valid='valid', ds_tfms=get_transforms(), size=224, bs=48)\n",
        "# normalize the image data so it has a mean of 0.5 and standard deviation of 0.5\n",
        "clean_data.normalize(([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYuv1acXYaNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_data.show_batch(rows=3, figsize=(7,6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMw_Z0KuYxhH",
        "colab_type": "text"
      },
      "source": [
        "## Training a Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbq5IrOlhyg8",
        "colab_type": "text"
      },
      "source": [
        "Now the data is loaded, run the cell below to create an image classification model which is based on the ResNet34 [convolutional neural network](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) (CNN) architecture, and pretrained on ImageNet, a database of over 14 million images. Since the model has been pretrained on an image recognition problem, we will be able to fine-tune it for this specific problem much quicker than if we started from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uP5O-ldYgij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_resnet34 = cnn_learner(clean_data, models.resnet34, metrics=error_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGMS-i55jLhv",
        "colab_type": "text"
      },
      "source": [
        "Run the cell below to train the model. The one argument we pass to the fit_one_cycle function is the number of times the model looks over the whole dataset. Each loop over the whole dataset, known as an epoch, should take about 1 minute 30 seconds. You can choose a number of epochs - 6 should lead to an error_rate of around 10%, i.e around 90% accuracy. Keep in mind this dataset has 12 categories, so random guessing mean around 8% accuracy. Also, if you run this cell more than once, training will continue from the previous time, since training updates the parameters of the model directly. \n",
        "\n",
        "The 'loss' in the table refers to a measure of how far the model's outputs were to the desired outputs which are part of the training set. Training involves calculating the partial derivative of all of the parameters (internal vairables which we can change to change the model's behaviour) of the model with respect to the loss, so that we know whether to make each parameter bigger or smaller to make the loss lower next time. This is what makes this technique 'differentiable' programming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmOn_U6LZFck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_resnet34.fit_one_cycle(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqCUn6Tykyit",
        "colab_type": "text"
      },
      "source": [
        "Run the following cell to save the parameters of the trained model - we'll need to load this saved model again later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u30P6f4tcyHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_resnet34.save('resnet34')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vvO_I5QiWpb",
        "colab_type": "text"
      },
      "source": [
        "## Training a Classifier: Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phFBnwLqk7Zn",
        "colab_type": "text"
      },
      "source": [
        "Run the following four cells to evaluate and plot the accuracy of the model we've trained. The confusion matrix is a plot of actual categories vs. predicted categories, and if the model has been sufficiently trained, the highest numbers should be along the diagonal, which corresponds to correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G3aQv8WhXfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp_classifier_resnet34 = ClassificationInterpretation.from_learner(classifier_resnet34)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pea1PWXePbCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp_classifier_resnet34.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ10mEubirWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_from_confusion_matrix(confusion_matrix):\n",
        "  return confusion_matrix.diagonal().sum() / confusion_matrix.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS6oSC4Ti2cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_from_confusion_matrix(interp_classifier_resnet34.confusion_matrix())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW5bDY7CjI-r",
        "colab_type": "text"
      },
      "source": [
        "## Generating Adversarial Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvRha1Ixlc8L",
        "colab_type": "text"
      },
      "source": [
        "These deep learning algorithms are incredibly powerful, and have [many uses](http://www.yaronhadad.com/deep-learning-most-amazing-applications/) beyond image recognition, but they are not without their weaknesses. It can be surprisingly easy to create inputs which look perfectly normal to a person, but which completely fool the model. These are known as adversarial examples, and they can have serious implications, especially when models are used in critical applications, like real-time computer vision in self-driving cars or drones. (These applications would use a camera input, but similar principles can be used to create [physical objects](https://bair.berkeley.edu/blog/2017/12/30/yolo-attack/) which fool the model.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Eu34jRn5b5",
        "colab_type": "text"
      },
      "source": [
        "Run the following cell to define a function to convert normal images to create adversarial ones. Basically, it alters the pixel data of the image to increase the error of the model in the same way as the parameters of the model are updated to decrease the error during usual training. This is the most basic method, and samples created this way will be unlikely to fool other models, but the general principle is the same for more sophisticated methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnSb7TEoi6NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fast_gradient_sign(img, label, e, model):\n",
        "  # keep track of the gradients (partial derivatives) of the image's pixel data\n",
        "  img.requires_grad = True\n",
        "  # get the model's output when it is passed the image\n",
        "  out = model(img)\n",
        "  # calculate the loss using the cross entropy loss function\n",
        "  loss = F.cross_entropy(out, label)\n",
        "  # calculate the partial derivatives of the pixel data\n",
        "  loss.backward()\n",
        "  # get whether these derivatives are positive or negative\n",
        "  s = img.grad.sign()\n",
        "  # update each pixel by a tiny amount in the direction which would cause the loss\n",
        "  # to increase. If the gradient/slope/paritial derivative of the loss function with\n",
        "  # respect to part of a pixel is positive, making that number bigger would increase\n",
        "  # the loss, and vice versa. \n",
        "  img_adv = img + e * s\n",
        "  return img_adv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyvsU4bBoo7i",
        "colab_type": "text"
      },
      "source": [
        "Now run the cell below to create a copy of the validation set where each image has been converted to an adversarial image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI3TpZOljt0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a path for the adversarial images. 'Untargeted' refers to the fact that\n",
        "# this method simply tries to get the model to make any wrong prediction, not\n",
        "# a specific wrong prediction\n",
        "adv_untargeted_valid_path = dataset_path/'valid_adv_untargeted'\n",
        "adv_untargeted_valid_path.mkdir(exist_ok=True)\n",
        "# for each category\n",
        "for i, category in enumerate(categories):\n",
        "  # create a folder for that category\n",
        "  (adv_untargeted_valid_path/category).mkdir(exist_ok=True)\n",
        "  # for each file in the validation set (and generate a progress bar)\n",
        "  for file in tqdm((valid_path/category).ls(), desc=category):\n",
        "    # open the image\n",
        "    img = Image.open(file).convert('RGB')\n",
        "    # covert the image to a PyTorch tensor (basically a fancy multi-dimensional array)\n",
        "    img_as_tensor = TF.normalize(TF.to_tensor(TF.resize(img, 224)), \n",
        "                                 (0.5, 0.5, 0.5), \n",
        "                                 (0.5, 0.5, 0.5))\n",
        "    # use our fast gradient sign function to alter the image tensor\n",
        "    img_adv_as_tensor = fast_gradient_sign(img_as_tensor.unsqueeze(0).cuda(), \n",
        "                                           torch.tensor([i]).cuda(),\n",
        "                                           0.001,\n",
        "                                           classifier_resnet34.model)\n",
        "    # convert the image back to a python image\n",
        "    img_adv = TF.to_pil_image(img_adv_as_tensor.squeeze().detach().cpu() * 0.5 + 0.5)\n",
        "    # save to disk\n",
        "    img_adv.save(adv_untargeted_valid_path/category/file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RBSUZtyo3QU",
        "colab_type": "text"
      },
      "source": [
        "We can now load this adversarial data using fastai, and show a few of the images to make sure they look normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HZiXy6gkqXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_adv_untargeted = ImageDataBunch.from_folder(dataset_path,\n",
        "                                                 train='train',\n",
        "                                                 valid = adv_untargeted_valid_path.name,\n",
        "                                                 ds_tfms=get_transforms(),\n",
        "                                                 size=224,\n",
        "                                                 bs=48)\n",
        "data_adv_untargeted.normalize(([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1M8Y271kxaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_adv_untargeted.show_batch(rows=3, figsize=(7,6), ds_type=DatasetType.Valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sakc8DU4qJqp",
        "colab_type": "text"
      },
      "source": [
        "## Generating Adversarial Examples (Results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IocyFuZgpFI_",
        "colab_type": "text"
      },
      "source": [
        "Run the following cell to create a copy of the original model which uses the adversarial validaiton set, so we can check the model's accuracy on it. Rather than training the model again, we'll load the previously saved model data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFh8qNQ0qBlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_resnet34_adv_untargeted = cnn_learner(data_adv_untargeted,\n",
        "                                                 models.resnet34,\n",
        "                                                 metrics=error_rate,\n",
        "                                                 pretrained=False)\n",
        "classifier_resnet34_adv_untargeted.load('resnet34');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dobsaggdpUFe",
        "colab_type": "text"
      },
      "source": [
        "Run the next three cells to check the model's accuracy on the adversarial data. You should see a much more scattered confusion matrix and a very low accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHKc4nX0rSQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp_resnet34_adv_untargeted = ClassificationInterpretation.from_learner(classifier_resnet34_adv_untargeted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnxvvJNvrffW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp_resnet34_adv_untargeted.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlNjA4LGrkry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_from_confusion_matrix(interp_resnet34_adv_untargeted.confusion_matrix())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfgLPjzGtILq",
        "colab_type": "text"
      },
      "source": [
        "## Generating Targeted Adversarial Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnuvpA2pwsD",
        "colab_type": "text"
      },
      "source": [
        "The adversarial examples generated above were not targeted to a specific class - the aim was simply for the model to fail to classify them correctly. We can also generate adversarial examples which are targeted, so the model will produce a specific wrong result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cSJ34uTqHns",
        "colab_type": "text"
      },
      "source": [
        "Run the next two code cells to define functions to do just this. This time, we'll alter the images multiple times in sequence, which will improve their effectiveness (but they will be more bound to this specific model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ1PTce4RuIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return altered image which attempts to make the model classify it as the given label\n",
        "def fast_gradient_sign_targeted(img, label, e, model):\n",
        "  img.requires_grad = True\n",
        "  out = model(img)\n",
        "  loss = F.cross_entropy(out, label)\n",
        "  loss.backward()\n",
        "  s = img.grad.sign()\n",
        "  x_adv = img - e * s\n",
        "  return x_adv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdzPdlbSTth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alter the image a number of times in sequence\n",
        "def fast_gradient_sign_targeted_iterative(img, label, e, it, model):\n",
        "  for _ in range(it):\n",
        "    x_adv = fast_gradient_sign_targeted(img, label, e, model)\n",
        "    img = x_adv.detach()\n",
        "  return x_adv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBP6gO_VqyAE",
        "colab_type": "text"
      },
      "source": [
        "The next three cells will select a false target category for each true category and create a copy of the validation set composed of targeted adversarial examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiGkGZgZvAbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a target category for each real category\n",
        "random.seed(12)\n",
        "target_categories = []\n",
        "for i in range(len(categories)):\n",
        "  other_categories = list(range(12))\n",
        "  other_categories.remove(i)\n",
        "  target_categories.append(random.choice(other_categories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J84-5_KZvnMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqmPEY9fuesd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a copy of the validation set where each image is a targeted adversarial example\n",
        "adv_targeted_valid_path = dataset_path/'valid_adv_targeted'\n",
        "adv_targeted_valid_path.mkdir(exist_ok=True)\n",
        "for i, category in enumerate(categories):\n",
        "  (adv_targeted_valid_path/category).mkdir(exist_ok=True)\n",
        "  print(category + ' -> ' + categories[target_categories[i]])\n",
        "  for file in tqdm((valid_path/category).ls()):\n",
        "    img = Image.open(file).convert('RGB')\n",
        "    img_as_tensor = TF.normalize(TF.to_tensor(TF.resize(img, 224)), \n",
        "                                 (0.5, 0.5, 0.5), \n",
        "                                 (0.5, 0.5, 0.5))\n",
        "    img_adv_as_tensor = fast_gradient_sign_targeted_iterative(img_as_tensor.unsqueeze(0).cuda(), \n",
        "                                           torch.tensor([target_categories[i]]).cuda(),\n",
        "                                           0.0002,\n",
        "                                           40,\n",
        "                                           classifier_resnet34.model)\n",
        "    img_adv = TF.to_pil_image(img_adv_as_tensor.squeeze().detach().cpu() * 0.5 + 0.5)\n",
        "    img_adv.save(adv_targeted_valid_path/category/file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gY-EJgIrLQf",
        "colab_type": "text"
      },
      "source": [
        "Now run the next two cells to load this data and display it to confirm they look like regular images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qPo-eVcc7P2H",
        "colab": {}
      },
      "source": [
        "data_adv_targeted = ImageDataBunch.from_folder(dataset_path,\n",
        "                                               train='train',\n",
        "                                               valid = adv_targeted_valid_path.name,\n",
        "                                               ds_tfms=get_transforms(),\n",
        "                                               size=224,\n",
        "                                               bs=48)\n",
        "data_adv_targeted.normalize(([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "naWqsZoz7P2T",
        "colab": {}
      },
      "source": [
        "data_adv_targeted.show_batch(rows=3, figsize=(7,6), ds_type=DatasetType.Valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ1mzCoi7DET",
        "colab_type": "text"
      },
      "source": [
        "## Generating Adversarial Examples (Targeted, White-box): Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGkbrG41rUT6",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can check the model's performance on these targeted adversarial examples. As before, we create a copy of the model and load the saved state, and generate a confusion matrix. You should find the results are concentrated in particular cells corresponding to the target categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3pOav4G7JDp",
        "colab": {}
      },
      "source": [
        "classifier_resnet34_adv_targeted = cnn_learner(data_adv_targeted,\n",
        "                                               models.resnet34,\n",
        "                                               metrics=error_rate,\n",
        "                                               pretrained=False)\n",
        "classifier_resnet34_adv_targeted.load('resnet34');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EQtohvp17JEB",
        "colab": {}
      },
      "source": [
        "interp_resnet34_adv_targeted = ClassificationInterpretation.from_learner(classifier_resnet34_adv_targeted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B79ZTxf_7JEL",
        "colab": {}
      },
      "source": [
        "interp_resnet34_adv_targeted.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKuhHomQ7JEU",
        "colab": {}
      },
      "source": [
        "accuracy_from_confusion_matrix(interp_resnet34_adv_targeted.confusion_matrix())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zEjtQ9G7jGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETcvfcKZr_qM",
        "colab_type": "text"
      },
      "source": [
        "We can also check how well the model followed our target categories. This should be very high."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wENFDvFoM0oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def targeted_accuracy(interp):\n",
        "  hits = 0\n",
        "  for i in range(12):\n",
        "    hits += interp.confusion_matrix()[i,target_categories[i]]\n",
        "  return hits / interp.confusion_matrix().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTspXwBe8DPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targeted_accuracy(interp_resnet34_adv_targeted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZffBBD1sRQm",
        "colab_type": "text"
      },
      "source": [
        "##Further resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1v6jMOasVTd",
        "colab_type": "text"
      },
      "source": [
        "There is a lot more you can do with deep learning using fastai and other libraries. https://course.fast.ai is home to an excellent series of video courses which have accompanying interactive notebooks like this one. You can have a look at some of these by clicking File -> Open notebook... and going to the GitHub tab. Type in fastai/course-v3 in the seach bar and look for notebooks in the nbs/dl1 directory. Also, there are several good PyTorch tutorials on the [PyTorch website](https://pytorch.org/tutorials/)."
      ]
    }
  ]
}